{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waytoakash/waytoakash/blob/main/Best_Match_Society_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqoo64LSmpUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0168dbb-7527-49fb-c044-f805aa6f7e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-442248655c4c>:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df11['distance_km'] = df11.apply(lambda row: geodesic((row['latitude'], row['longitude']), (row['Store_Latitude'], row['Store_Longitude'])).kilometers, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 4.0130 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-442248655c4c>:110: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df12['distance_km'] = df12.apply(lambda row: geodesic((row['latitude'], row['longitude']), (row['Store_Latitude'], row['Store_Longitude'])).kilometers, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 3.9543 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-442248655c4c>:120: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df13['distance_km'] = df13.apply(lambda row: geodesic((row['latitude'], row['longitude']), (row['Store_Latitude'], row['Store_Longitude'])).kilometers, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 3.9808 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-442248655c4c>:131: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_cata.rename(columns={'id':'Society ID','distance_km':'Distance Between Store & Society'},inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from functools import reduce\n",
        "import time\n",
        "from geopy.distance import geodesic\n",
        "from google.colab import drive, auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "def changeDateFormat(row):\n",
        "    return pd.to_datetime(row, errors='coerce').dt.date\n",
        "\n",
        "def cleanText(row):\n",
        "    return row.str.upper().str.strip()\n",
        "\n",
        "def get_data(spreadSheetId, rangeName):\n",
        "    wb = gc.open_by_key(spreadSheetId)\n",
        "    ws = wb.worksheet(rangeName)\n",
        "    rows = ws.get_all_values()\n",
        "    return rows\n",
        "\n",
        "def gdata(spreadSheetId, rangeName):\n",
        "    l = get_data(spreadSheetId, rangeName)\n",
        "    ldf = pd.DataFrame.from_records(l[1:], columns=l[0])\n",
        "    return ldf\n",
        "\n",
        "def sdata(spreadsheet_id, sheet_name, dataframe, start_row=1, start_col=1):\n",
        "    wb = gc.open_by_key(spreadsheet_id)\n",
        "    ws = wb.worksheet(sheet_name)\n",
        "    range_to_clear = f\"{sheet_name}!A{start_row}:ZZZ\"\n",
        "    wb.values_clear(range_to_clear)\n",
        "    set_with_dataframe(ws, dataframe, row=start_row, col=start_col)\n",
        "\n",
        "def clean_numeric_columns(df, columns):\n",
        "    for column in columns:\n",
        "        # Remove non-numeric characters\n",
        "        df[column] = df[column].str.extract(r'([0-9\\.\\-]+)').astype(float)\n",
        "    return df\n",
        "\n",
        "daysDelta = 0\n",
        "DumpDate =  pd.to_datetime((datetime.today() - timedelta(days = daysDelta)).date()).strftime('%d %B %Y')\n",
        "file_path = \"/content/drive/MyDrive/Insights_Datalake/Datewise Dumps - Aug Onwards/\"+(datetime.today() - timedelta(days = daysDelta)).strftime(\"%b %Y\")+\"/\"\n",
        "\n",
        "sm=gdata(\"1aVAu23rPNHyOEk2ioNXdbqyUKEFzcXedlY283cvDKvY\",\"Society Master\")\n",
        "sm=sm[sm['Society status']=='ACTIVE']\n",
        "sm=sm[['Kibana ID','Society Name']]\n",
        "sm.rename(columns={'Kibana ID':'id'},inplace=True)\n",
        "dump_name = \"Society Creation Date - Insights Copy\"\n",
        "\n",
        "scd = pd.read_csv(file_path + DumpDate + \"/Sai/\"+ dump_name +\".csv\",parse_dates=True)\n",
        "scd=scd[['id','latitude', 'longitude']]\n",
        "\n",
        "scd['latitude'] = scd['latitude'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)\n",
        "scd['longitude'] = scd['longitude'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)\n",
        "\n",
        "scd[['latitude', 'longitude']] = scd[['latitude', 'longitude']]/1000000\n",
        "\n",
        "sm=sm.merge(scd,on='id',how='left')\n",
        "sm.drop_duplicates(keep='first',inplace=True)\n",
        "sm=sm[(sm['latitude'].notna()) & (sm['longitude'].notna())]\n",
        "\n",
        "js=gdata(\"1y8dDnmbFl2IInlhzeCLZq9XhPoSL6VjF5F2MtihAudo\",\"Store Data\")\n",
        "js=js[['Store Code','Store_Latitude', 'Store_Longitude','Enter The Distance Limit']]\n",
        "\n",
        "# Clean the columns\n",
        "js = clean_numeric_columns(js, ['Store_Latitude', 'Store_Longitude', 'Enter The Distance Limit'])\n",
        "\n",
        "js[['Store_Latitude', 'Store_Longitude','Enter The Distance Limit']]=js[['Store_Latitude', 'Store_Longitude','Enter The Distance Limit']].astype(float)\n",
        "js['Remark'] = 'Invalid'\n",
        "js.loc[(js['Store_Latitude'] >= 8.4) & (js['Store_Latitude'] <= 37.6) &\n",
        "       (js['Store_Longitude'] >= 68.1) & (js['Store_Longitude'] <= 97.4), 'Remark'] = 'Valid'\n",
        "js=js[js['Remark']=='Valid']\n",
        "\n",
        "def calculate_distance(row):\n",
        "    society_coords = (row['latitude'], row['longitude'])\n",
        "    store_coords = (row['Store_Latitude'], row['Store_Longitude'])\n",
        "    return geodesic(society_coords, store_coords).kilometers\n",
        "\n",
        "# Assuming df1 is the society dataframe and df2 is the store dataframe\n",
        "result = pd.merge(sm, js, how='cross')\n",
        "\n",
        "# Split 'df1' into three parts\n",
        "total_size = len(result)\n",
        "part_size = total_size // 3\n",
        "df11 = result.iloc[:part_size]\n",
        "df12 = result.iloc[part_size:2*part_size]\n",
        "df13 = result.iloc[2*part_size:]\n",
        "#1st part\n",
        "st=time.time()\n",
        "df11['distance_km'] = df11.apply(lambda row: geodesic((row['latitude'], row['longitude']), (row['Store_Latitude'], row['Store_Longitude'])).kilometers, axis=1)\n",
        "et=time.time()\n",
        "\n",
        "elapsed_time_minutes = (et - st) / 60\n",
        "\n",
        "# Print the elapsed time in minutes\n",
        "print(f\"Elapsed time: {elapsed_time_minutes:.4f} minutes\")\n",
        "\n",
        "#2nd part\n",
        "st=time.time()\n",
        "df12['distance_km'] = df12.apply(lambda row: geodesic((row['latitude'], row['longitude']), (row['Store_Latitude'], row['Store_Longitude'])).kilometers, axis=1)\n",
        "et=time.time()\n",
        "\n",
        "elapsed_time_minutes = (et - st) / 60\n",
        "\n",
        "# Print the elapsed time in minutes\n",
        "print(f\"Elapsed time: {elapsed_time_minutes:.4f} minutes\")\n",
        "\n",
        "#3rd part\n",
        "st=time.time()\n",
        "df13['distance_km'] = df13.apply(lambda row: geodesic((row['latitude'], row['longitude']), (row['Store_Latitude'], row['Store_Longitude'])).kilometers, axis=1)\n",
        "et=time.time()\n",
        "\n",
        "elapsed_time_minutes = (et - st) / 60\n",
        "\n",
        "# Print the elapsed time in minutes\n",
        "print(f\"Elapsed time: {elapsed_time_minutes:.4f} minutes\")\n",
        "pdata=pd.concat([df11,df12,df13])\n",
        "pdata=pdata[(pdata['distance_km'] <= pdata['Enter The Distance Limit'])].sort_values(['id','distance_km'])\n",
        "pdata_s=pdata.drop_duplicates('id',keep='first')\n",
        "final_cata=pdata_s[['Store Code','id','Society Name','distance_km']]\n",
        "final_cata.rename(columns={'id':'Society ID','distance_km':'Distance Between Store & Society'},inplace=True)\n",
        "final_cata=final_cata[['Store Code','Society ID','Society Name','Distance Between Store & Society']]\n",
        "\n",
        "l = get_data(\"1YmTPZYOv1iP6jwnL_kGEchHEv7TkhZIh0c5HBp63lR4\", 'Helper')\n",
        "df2 = pd.DataFrame.from_records(l[1:], columns=l[0])\n",
        "\n",
        "l = get_data(\"1vVgJJdS5-qu9ga6Hag0WRuSSAUGI1WrWnWsgRRMir_g\", 'Helper')\n",
        "prm = pd.DataFrame.from_records(l[1:], columns=l[0])\n",
        "prm=prm[['Kibana ID','Premiumness']]\n",
        "df2=pd.merge(df2,prm,on='Kibana ID',how='left')\n",
        "\n",
        "df2=df2[['City', 'Kibana ID', 'Original Closure Number',\n",
        "       'Society status', 'Live Product', 'Latest Signing Date', 'Sold Flats',\n",
        "       'KAM Usage', 'Sr.KAM Usage', 'Download %',\n",
        "       'Open to Sales Status-ERP', 'Open to Sales Status-VMS',\n",
        "       'Status', 'Rent Range',\n",
        "       'Locality (Automated Through Latlong)', 'Premiumness', 'pincode',\n",
        "       'Locality', 'fashion quartile', 'food quartile', 'grocery quartile',\n",
        "       'cabs quartile', 'ecom quartile', 'female to male ratio',\n",
        "       'Pet Quartiles', 'Owner Residing penetration',\n",
        "       'No: of Activity done in last  6 months']]\n",
        "\n",
        "df2 = df2.loc[:, ~df2.columns.duplicated()]\n",
        "\n",
        "\n",
        "\n",
        "'''df2=df2[['City', 'Kibana ID', 'Original Closure Number',\n",
        "       'societyStatus', 'Live Product', 'Latest Signing Date', 'Sold Flats',\n",
        "       'KAM Usage', 'Sr.KAM Usage', 'Download %',\n",
        "       'Open to Sales Status-ERP', 'Open to Sales Status-VMS',\n",
        "       'Status', 'latitude', 'longitude', 'Rent Range',\n",
        "       'Locality (Automated Through Latlong)', 'Premiumness', 'pincode',\n",
        "       'Locality', 'fashion quartile', 'food quartile', 'grocery quartile',\n",
        "       'cabs quartile', 'ecom quartile', 'female to male ratio',\n",
        "       'Pet Quartiles', 'Owner Residing penetration',\n",
        "       'No: of Activity done in last  6 months']]'''\n",
        "df2.rename(columns={'Kibana ID':'Society ID'},inplace=True)\n",
        "final_cata=final_cata.merge(df2,on='Society ID',how='left')\n",
        "\n",
        "\n",
        "\n",
        "#Pushing to sheet\n",
        "spreadsheet_id='1y8dDnmbFl2IInlhzeCLZq9XhPoSL6VjF5F2MtihAudo'\n",
        "sheet_name= \"Best Match Result\"\n",
        "start_row=1\n",
        "start_col=1\n",
        "wb = gc.open_by_key(spreadsheet_id)\n",
        "ws = wb.worksheet(sheet_name)\n",
        "range_to_clear = f\"{sheet_name}!A{start_row}:AM\"\n",
        "wb.values_clear(range_to_clear)\n",
        "set_with_dataframe(ws, final_cata, row=start_row, col=start_col)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0RnA7KOSL3E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}